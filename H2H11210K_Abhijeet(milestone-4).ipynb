{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1305dd39",
   "metadata": {},
   "source": [
    "##H2H11210K\n",
    "## Milestone 4 - ML Models and Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7bb2bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Modify the dataset to pass into any type of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b3815818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical colums: \n",
      " Index(['CUSTOMER_ORDER_ID', 'SALES_ORG', 'DISTRIBUTION_CHANNEL', 'DIVISION',\n",
      "       'RELEASED_CREDIT_VALUE', 'PURCHASE_ORDER_TYPE', 'COMPANY_CODE',\n",
      "       'ORDER_CREATION_TIME', 'CREDIT_CONTROL_AREA', 'SOLD_TO_PARTY',\n",
      "       'ORDER_AMOUNT', 'ORDER_CURRENCY', 'CREDIT_STATUS', 'CUSTOMER_NUMBER',\n",
      "       'amount_in_usd', 'unique_cust_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "numerical_columns = df.select_dtypes(include=['int', 'float']).columns\n",
    "print(\"Numerical colums: \\n\", numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d972ea51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUSTOMER_ORDER_ID                   int64\n",
      "SALES_ORG                           int64\n",
      "DISTRIBUTION_CHANNEL                int32\n",
      "DIVISION                            int32\n",
      "RELEASED_CREDIT_VALUE             float64\n",
      "PURCHASE_ORDER_TYPE                 int32\n",
      "COMPANY_CODE                        int64\n",
      "ORDER_CREATION_DATE        datetime64[ns]\n",
      "ORDER_CREATION_TIME                 int64\n",
      "CREDIT_CONTROL_AREA                 int32\n",
      "SOLD_TO_PARTY                       int64\n",
      "ORDER_AMOUNT                      float64\n",
      "REQUESTED_DELIVERY_DATE    datetime64[ns]\n",
      "ORDER_CURRENCY                      int32\n",
      "CREDIT_STATUS                       int32\n",
      "CUSTOMER_NUMBER                     int64\n",
      "amount_in_usd                     float64\n",
      "unique_cust_id                      int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d372c678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the irrelevant columns\n",
    "\n",
    "irrelevant_columns = ['CREDIT_CONTROL_AREA', 'SOLD_TO_PARTY', 'CUSTOMER_ORDER_ID']\n",
    "df = df.drop(irrelevant_columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd5946a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target variable and store in the y as the dependent variable\n",
    "\n",
    "X = df.drop('amount_in_usd', axis=1)\n",
    "y = df['amount_in_usd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4af9911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot Encoding on all the independent features' columns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "x_encoded = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "682bc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing subsets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_encoded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6023b81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing data with StandardScaler() function.\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "256e68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Try different machine learning models like -\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15db1bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a. Linear Regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec466a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "linear_regression = LinearRegression()\n",
    "support_vector_machine = SVR()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "random_forest = RandomForestRegressor()\n",
    "adaboost = AdaBoostRegressor()\n",
    "xgboost = XGBRegressor()\n",
    "\n",
    "models = [linear_regression, support_vector_machine, decision_tree, random_forest, adaboost, xgboost]\n",
    "model_names = ['Linear Regression', 'Support Vector Machine', 'Decision Tree', 'Random Forest', 'AdaBoost', 'XGBoost']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f'{name}: RMSE = {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ee0776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Support Vector Machine\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "support_vector_machine = SVR()\n",
    "support_vector_machine.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6345521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Decision Tree\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "\n",
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5c8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. AdaBoost\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "\n",
    "adaboost = AdaBoostRegressor()\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb78035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f. Xgboost \n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgboost = XGBRegressor()\n",
    "xgboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e18dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Perform Regression model evaluations like MSE, RMSE, R-Square etc.\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "models = [linear_regression, support_vector_machine, decision_tree, random_forest, adaboost, xgboost]\n",
    "model_names = ['Linear Regression', 'Support Vector Machine', 'Decision Tree', 'Random Forest', 'AdaBoost', 'XGBoost']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    \n",
    "    print(f'{name}:')\n",
    "    print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "    print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "    print(f'R-squared: {r2:.4f}')\n",
    "    print(f'Mean Absoluate Error: {mae:.4f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eeb6886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Mean Squared Error (MSE): 1.7949\n",
      "Root Mean Squared Error (RMSE): 1.3397\n",
      "R-squared: 0.8084\n",
      "Mean Absoluate Error: 0.4726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# a. Linear Regression model evaluations\n",
    "\n",
    "y_pred = linear_regression.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Linear Regression:')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Absoluate Error: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df84b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b. Support Vector Machine model evaluations\n",
    "\n",
    "y_pred = support_vector_machine.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Support Vector Machine:')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Absoluate Error: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26447998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Decision Tree model evaluations\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Decision Tree:')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Absoluate Error: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3cac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Random Forest model evaluations\n",
    "\n",
    "y_pred = random_forest.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('Random Forest:')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Absoluate Error: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. AdaBoost model evaluations\n",
    "\n",
    "y_pred = adaboost.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('AdaBoost Prediction:')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Absoluate Error: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0bad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f. Xgboost model evaluations\n",
    "\n",
    "y_pred = xgboost.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('XGBoost Prediction:')\n",
    "print(f'Mean Squared Error (MSE): {mse:.4f}')\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse:.4f}')\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Absoluate Error: {mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c062b099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compare the accuracies of all the models\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "models = [linear_regression, support_vector_machine, decision_tree, random_forest, adaboost, xgboost]\n",
    "model_names = ['Linear Regression', 'Support Vector Machine', 'Decision Tree', 'Random Forest', 'AdaBoost', 'XGBoost']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f'{name}: R-squared = {r2:.4f}')\n",
    "\n",
    "r2_values = [r2_score(y_test, model.predict(X_test)) for model in models]\n",
    "\n",
    "plt.bar(model_names, r2_values)\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('R-squared')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92482d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Select the best possible model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ae56838",
   "metadata": {},
   "source": [
    "In the provided list of regression models, you can evaluate the models based on their performance metrics such as \n",
    "R-squared,mean squared error (MSE), and root mean squared error (RMSE). Generally, a higher R-squared value and lower \n",
    "MSE/RMSE indicate better model performance.\n",
    "\n",
    "To select the best possible model, you can compare the performance metrics of the models and choose the one that achieves \n",
    "the highest R-squared value and the lowest MSE/RMSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f40f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "k = 5\n",
    "\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "mse_scores = []\n",
    "rmse_scores = []\n",
    "r2_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X_train):\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "    \n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    y_pred_fold = model.predict(X_val_fold)\n",
    "    \n",
    "    mse = mean_squared_error(y_val_fold, y_pred_fold)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = model.score(X_val_fold, y_val_fold)\n",
    "    \n",
    "    mse_scores.append(mse)\n",
    "    rmse_scores.append(rmse)\n",
    "    r2_scores.append(r2)\n",
    "\n",
    "avg_mse = np.mean(mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "avg_r2 = np.mean(r2_scores)\n",
    "\n",
    "print(\"Average MSE:\", avg_mse)\n",
    "print(\"Average RMSE:\", avg_rmse)\n",
    "print(\"Average R-squared:\", avg_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4f6122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Perform Hyperparameter tuning, select best hyperparameters by using appropriate algorithms.\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = { }\n",
    "# model = YourModel()\n",
    "\n",
    "# grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# best_params = grid_search.best_params_\n",
    "\n",
    "# best_model = grid_search.best_estimator_\n",
    "\n",
    "# y_pred = best_model.predict(X_test)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# r2 = best_model.score(X_test, y_test)\n",
    "\n",
    "# print(\"Best Hyperparameters:\", best_params)\n",
    "# print(\"Best Model MSE:\", mse)\n",
    "# print(\"Best Model RMSE:\", rmse)\n",
    "# print(\"Best Model R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9364fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Come up with the best possible model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# y_pred = linear_regression.predict(X_test)\n",
    "\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# precision = precision_score(y_test, y_pred)\n",
    "# recall = recall_score(y_test, y_pred)\n",
    "# f1 = f1_score(y_test, y_pred)\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# print(\"\\nAccuracy:\", accuracy)\n",
    "# print(\"\\nPrecision:\", precision)\n",
    "# print(\"\\nRecall:\", recall)\n",
    "# print(\"\\nF1 Score:\", f1)\n",
    "# print(\"\\nConfusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48a749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot the roc and auc curves\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0f1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "# plt.plot([0, 1], [0, 1], 'k--')\n",
    "# plt.xlabel('False Positive Rate')\n",
    "# plt.ylabel('True Positive Rate')\n",
    "# plt.title('Receiver Operating Characteristic')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(\"AUC Score:\", roc_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
